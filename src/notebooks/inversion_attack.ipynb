{
 "cells": [
  {
   "source": [
    "ON THE HUMAN-RECOGNIZABILITY PHENOMENON OF ADVERSARIALLY TRAINED DEEP IMAGE CLASSIFIERS\n",
    "\n",
    "Copyright 2020 Carnegie Mellon University.\n",
    "\n",
    "NO WARRANTY. THIS CARNEGIE MELLON UNIVERSITY AND SOFTWARE ENGINEERING INSTITUTE \n",
    "MATERIAL IS FURNISHED ON AN \"AS-IS\" BASIS. CARNEGIE MELLON UNIVERSITY MAKES NO \n",
    "WARRANTIES OF ANY KIND, EITHER EXPRESSED OR IMPLIED, AS TO ANY MATTER INCLUDING, \n",
    "BUT NOT LIMITED TO, WARRANTY OF FITNESS FOR PURPOSE OR MERCHANTABILITY, \n",
    "EXCLUSIVITY, OR RESULTS OBTAINED FROM USE OF THE MATERIAL. CARNEGIE MELLON \n",
    "UNIVERSITY DOES NOT MAKE ANY WARRANTY OF ANY KIND WITH RESPECT TO FREEDOM FROM \n",
    "PATENT, TRADEMARK, OR COPYRIGHT INFRINGEMENT.\n",
    "\n",
    "Released under a MIT (SEI)-style license, please see license.txt or contact permission@sei.cmu.edu for full terms.\n",
    "\n",
    "[DISTRIBUTION STATEMENT A] This material has been approved for public release and unlimited distribution.  \n",
    "Please see Copyright notice for non-US Government use and distribution.\n",
    "\n",
    "Carnegie MellonÂ® is registered in the U.S. Patent and Trademark Office by Carnegie Mellon University.\n",
    "This Software includes and/or makes use of the following Third-Party Software subject to its own license:\n",
    "\n",
    "1. Python (https://docs.python.org/3/license.html#psf-license-agreement-for-python-release) Copyright 2001-2020 \n",
    "Python Software Foundation 2001-2020.\n",
    "\n",
    "2. PyTorch (https://github.com/pytorch/pytorch/blob/master/LICENSE#L3-L11) Copyright 2016 Facebook Inc.\n",
    "\n",
    "3. Torchvision (https://github.com/pytorch/vision/blob/master/LICENSE) Copyright 2016 Soumith Chintala.\n",
    "\n",
    "4. NumPy (https://github.com/numpy/numpy/blob/master/LICENSE.txt) Copyright 2005-2020 NumPy Developers.\n",
    "\n",
    "5. tqdm (https://github.com/tqdm/tqdm/blob/master/LICENCE) Copyright noamraph 2013.\n",
    "\n",
    "6. Jupyter (https://github.com/jupyter/notebook/blob/master/LICENSE) Copyright IPython Development Team \n",
    "2001-2015, Jupyter Development Team 2015-2020 IPython Development Team 2001-2015, Jupyter Development \n",
    "Team 2015-2020.\n",
    "\n",
    "DM20-1153"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "from models.preact_resnet import PreActResNet18\n",
    "from attack.inversion import inversion\n",
    "from constants import (LABEL_MAP, \n",
    "                       CIFAR10_SHAPE,\n",
    "                       CIFAR10_MEAN, CIFAR10_STD, \n",
    "                       MU, STD,\n",
    "                       UPPER_LIMIT, LOWER_LIMIT)\n",
    "from utils import load_img, normalize_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.environ['DATA_DIR']\n",
    "assert os.path.isdir(data_dir)\n",
    "\n",
    "# `final` dir is not created by default, change this according to your own model directory structure\n",
    "model_dir = os.path.join(os.environ['OUT_DIR'], 'final')\n",
    "assert os.path.isdir(model_dir)\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "# list available models\n",
    "available_models = os.listdir(model_dir)\n",
    "available_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models = ['model_preact_resnet18_pgd.pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_model(model_name  :str):\n",
    "    pdict = torch.load(\n",
    "        os.path.join(model_dir, model_name),\n",
    "        map_location='cpu')\n",
    "    model = PreActResNet18()\n",
    "    assert len(pdict) == len(model.state_dict())\n",
    "    model.load_state_dict(pdict)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    model.requires_grad_(False)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = load_model(available_models[0])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD)])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD)])\n",
    "\n",
    "kwargs = dict(\n",
    "    batch_size =1,\n",
    "    shuffle    =True,\n",
    "    pin_memory =True,\n",
    "    num_workers=4)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    dataset=datasets.CIFAR10(data_dir, \n",
    "        train    =True, \n",
    "        transform=train_transform, \n",
    "        download =False), \n",
    "    **kwargs)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    dataset=datasets.CIFAR10(data_dir, \n",
    "        train    =False, \n",
    "        transform=test_transform, \n",
    "        download =False), \n",
    "    **kwargs)"
   ]
  },
  {
   "source": [
    "# Total & per-class accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all = []\n",
    "targets_all = []\n",
    "for data, target in tqdm(testloader, desc='Evaluating', total=len(testloader)):\n",
    "    targets_all.append(target)\n",
    "    \n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(data)\n",
    "        preds = logits.softmax(dim=1)\n",
    "        preds_all.append(preds.cpu())\n",
    "\n",
    "targets_all = torch.cat(targets_all)\n",
    "preds_all = torch.cat(preds_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_thresholds = torch.linspace(0.,1.,11)\n",
    "\n",
    "accuracies = []\n",
    "pred_labels = preds_all.argmax(dim=1)\n",
    "for i in range(len(LABEL_MAP)):\n",
    "    indices = (targets_all == i)\n",
    "    acc_i = (pred_labels[indices] == targets_all[indices]).float().mean()\n",
    "    accuracies.append(acc_i)\n",
    "\n",
    "print('Total: ', sum(accuracies).item() / len(accuracies))\n",
    "print()\n",
    "for i, acc in enumerate(accuracies):\n",
    "    print(f'{LABEL_MAP[i]}: {acc.item():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inversion attack via minimizing cross-entropy loss wrt target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "clamp = [\n",
    "    [(0. - mu) / std, (1. - mu) / std] \n",
    "    for mu, std in zip(CIFAR10_MEAN, CIFAR10_STD)]\n",
    "\n",
    "n_samples = len(LABEL_MAP)\n",
    "shape = CIFAR10_SHAPE\n",
    "x0 = STD * torch.empty(n_samples, *shape).uniform_(-1.,1.)\n",
    "for i in range(x0.shape[1]):\n",
    "    x0[:,i] = torch.clamp(x0[:,i], *clamp[i])\n",
    "    \n",
    "stepsize = 2. / 255.\n",
    "max_iters = 1024\n",
    "\n",
    "x_inv = inversion(\n",
    "    model    =model,\n",
    "    x0       =x0,\n",
    "    category =torch.arange(len(x0)),\n",
    "    stepsize =stepsize,\n",
    "    max_iters=max_iters,\n",
    "    clamp    =clamp,\n",
    "    geometry ='linf').cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,50))\n",
    "for i, img in enumerate(x_inv):\n",
    "    pred = model(img[None].to(device)).argmax(1).item()\n",
    "    \n",
    "    plt.subplot(1, len(x_inv), i + 1)\n",
    "    plt.imshow(normalize_img(img).permute(1,2,0))\n",
    "    plt.axis('off')\n",
    "    plt.title(f'{LABEL_MAP[i].split(\",\")[0]}', fontsize=64, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_y(target):\n",
    "    for x, y in testloader:\n",
    "        x = x.squeeze()\n",
    "        if y.item() == target:\n",
    "            found = True\n",
    "            return x\n",
    "        \n",
    "clamp = [\n",
    "    [(0. - MU) / STD, (1. - MU) / STD] \n",
    "    for MU, STD in zip(CIFAR10_MEAN, CIFAR10_STD)]\n",
    "\n",
    "# fix identical seeds\n",
    "seeds = [sample_from_y(y) for y in range(len(LABEL_MAP))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepsize = 1e-1\n",
    "max_iters = 16\n",
    "\n",
    "all_paths = []\n",
    "all_labels = []\n",
    "all_paths_adv = []\n",
    "all_preds_adv = []\n",
    "model_name = available_models[0]\n",
    "print(model_name)\n",
    "model = load_model(model_name)\n",
    "for target in tqdm(range(10)):\n",
    "    path = []\n",
    "    path_adv = []\n",
    "    pred_adv = []\n",
    "    num_queries = []\n",
    "    x0 = seeds[target].unsqueeze(0)\n",
    "    path.append(x0.clone())\n",
    "    for y in tqdm(range(10), desc='Targeting'):\n",
    "        x_inv = inversion(\n",
    "            model    =model,\n",
    "            x0       =x0,\n",
    "            category =y,\n",
    "            stepsize =stepsize,\n",
    "            max_iters=max_iters,\n",
    "            clamp    =clamp,\n",
    "            geometry ='linf').cpu()\n",
    "        \n",
    "        path_adv.append(x_inv)\n",
    "    \n",
    "    all_paths.append(path[0])\n",
    "    all_paths_adv.append(path_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "count = 1\n",
    "fontsize = 16\n",
    "fontweight = 'bold'\n",
    "for i, (path, path_adv) in enumerate(zip(all_paths, all_paths_adv)):\n",
    "    plt.subplot(10, len(path_adv) + 1, count)\n",
    "    count += 1\n",
    "    plt.imshow(normalize_img(path[0]).squeeze().permute(1,2,0))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.ylabel(f'{LABEL_MAP[i]}', fontsize=fontsize, fontweight=fontweight)\n",
    "    if i == 0:\n",
    "        plt.title('Seed $x_0$', fontsize=fontsize, fontweight=fontweight)\n",
    "    for j, img in enumerate(path_adv):\n",
    "        plt.subplot(10, len(path_adv) + 1, count)\n",
    "        count += 1\n",
    "        img = normalize_img(img).squeeze().permute(1,2,0)\n",
    "        ax = plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        if i == 0:\n",
    "            plt.title(f'{LABEL_MAP[j]}', fontsize=fontsize, fontweight=fontweight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}